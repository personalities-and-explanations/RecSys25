# README: Resource Repository
This is the online repository for the paper 'Towards Personality-Aware Explanations for Music Recommendations Using Generative AI'.

## Citation
If you use this dataset, code, or prompts in your research, please cite the following paper:


```bibtex
@inproceedings{2025personality,
  title     = {Towards Personality-Aware Explanations for Music Recommendations Using Generative AI},
  author    = {Gabrielle Alves and Dietmar Jannach and Luan Souza and Marcelo Manzato},
  booktitle = {Proceedings of the 19th ACM Conference on Recommender Systems (RecSys)},
  year      = {2025},
  isbn      = {979-8-4007-1364-4/2025/09},
  publisher = {Association for Computing Machinery},
  address   = {Prague, Czech Republic},
  doi       = {10.1145/3705328.3748032},
  url       = {https://doi.org/10.1145/3705328.3748032}
}
```
## Content of the Folders

### 1. Datasets:
1. **users_data.csv:** This file contains the primary dataset gathered during our main study. It includes user interactions, responses, and behavioral logs.
2. **explanations.csv:** Dataset of explanations generated by ChatGPT.
3. **standardized_residuals.csv:** This file contains the top 20% most frequently used words, which account for 80% of the interactions, based on the Pareto principle.

### 2. Prompts:
1. **final_prompts_english.json:** Contains the finalized prompt templates in English used to generate personality-aligned explanations for music recommendations.
2. **final_prompts_portuguese.json:** Contains the finalized prompt templates in Portuguese used to generate personality-aligned explanations for music recommendations.

### 3. Questions:
1. **questions_english_rq2.txt:** Contains the set of evaluation questions in English used to assess user perceptions of the explanations for Research Question 2 (RQ2).
2. **questions_portuguese_rq2.txt:** Contains the set of evaluation questions in Portuguese used to assess user perceptions of the explanations for Research Question 2 (RQ2).
   
### 4. Screens:
Multiple images showcasing the various interfaces that are part of the study, organized sequentially to match the progression in the experiment.

### 3. Scripts (with tables):

#### RQ1 – Explanation Preference
1. **RQ1_LexicalEvaluation.ipynb**: Scripts to translate, stem, and match explanation words to Big Five personality traits, and compute precision, recall, and F1-score to evaluate alignment.
2. **RQ1_chisquare.ipynb**: Script with the chi-square test to evaluate whether certain explanation types were selected more frequently than expected.


#### RQ2 – Explanation Evaluation
1. **RQ2_Friedman.ipynb**: Script with the Friedman and Wilcoxon tests to compare user ratings (e.g., quality, acuracy, persuasiveness) across explanation types.
2. **RQ2_chi.ipynb**: Script with the chi-square test to evaluate differences in categorical user ratings across explanation types.
3. **RQ2_meanSD.ipynb**: Script with the mean and standard deviation calculation for user ratings per explanation type and evaluation category.

